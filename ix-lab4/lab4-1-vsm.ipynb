{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *Your group letter.*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Name 1*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'actually', 'was', 'better', 'how', 'for', 'could', 'please', 'then', 'whereupon', 'so', 'consider', 'as', 'any', 'used', 'brief', 'why', 'several', 'hi', 'six', 'by', 'k', 'hence', 'yourself', 'looking', 'right', 'saying', 'fifth', 'wish', 'did', \"there's\", 'able', 'whose', 'uses', 'inward', 'appear', 'doing', 'her', 'yourselves', 'new', 'nothing', 'not', 'believe', 'thereby', 'got', 'took', \"c's\", \"we've\", 'each', 'whether', 'gets', 'obviously', 'serious', 'inner', 'perhaps', 'me', 'necessary', 'gotten', 'nevertheless', 'furthermore', 'looks', 'somebody', 'rather', 'elsewhere', 'former', 'seemed', 'away', 'up', 'than', 'except', 'via', 'can', 'everything', 'currently', \"you've\", 'along', 'already', 'while', 'selves', 'thus', 'our', 'anyone', 'must', 'either', 'c', \"c'mon\", 'try', 'wants', 'welcome', 'between', 'ever', 'z', 'does', 'whereafter', 'apart', 'gone', 'awfully', 'came', 'let', 'like', 'in', 'u', 'getting', 'again', 'taken', 'thank', 'itself', 'need', 'themselves', 'until', 'whence', \"they'll\", 'no', 'she', 'say', 'us', 'normally', 'amongst', 'greetings', 'nearly', 'despite', 'hither', \"i'll\", 'consequently', 'available', 'were', 'whole', 'knows', 'nine', 'thanx', 'everywhere', 'mainly', 'under', 'an', 'corresponding', 'therein', 'go', 'would', 'containing', 'causes', 'beyond', 'near', \"you're\", 'become', 'etc', 'liked', \"doesn't\", 'seriously', 'sure', 's', 'asking', 'uucp', 'merely', 'gives', 'myself', 'they', 'about', \"hasn't\", 'ie', 'indicates', 'far', \"i'd\", 'since', 'whatever', 'whereby', 'though', 'lately', 'nd', 'thru', \"isn't\", \"that's\", 'a', 'plus', \"haven't\", \"hadn't\", 'never', 'cant', 'saw', 'viz', 'theres', 'their', 'unlikely', 'even', 'ours', \"can't\", 'am', 'someone', 'that', 'last', 'to', 'd', \"he's\", \"couldn't\", 'placed', 'becoming', 'upon', 'one', 'this', 'meanwhile', 'more', 'else', 'usually', 'definitely', 'hello', \"who's\", 'himself', 'moreover', 'tends', 'use', 'possible', 'regardless', 'well', \"shouldn't\", 'became', 'reasonably', 'same', 'b', 'everybody', 'j', 'alone', 'self', \"wasn't\", 'these', 'before', 'needs', 'goes', 'with', 'but', 'because', 'went', 'following', 'hers', 'really', 'thorough', 'thereupon', 'third', 'always', 'described', \"we'll\", 'some', 'associated', 'thanks', \"i've\", 'seen', 'think', 'hereby', 'his', \"what's\", 'above', 'going', 'twice', 'th', 'few', 'formerly', 'insofar', 'sensible', 'happens', 'maybe', 'however', 'seeming', 'having', 'co', 'somewhere', 'him', 'neither', 'okay', 'do', 'whereas', 'according', 'particularly', 'ask', 'howbeit', 'o', 'wherein', 'besides', \"they've\", 'contains', 'next', 'throughout', 'against', 'edu', 'et', 'is', 'unless', 'yet', 'therefore', 'many', 'eight', 'still', 'name', 'certainly', 'inc', 'nobody', 'sup', 'somehow', 'you', 'anybody', 'eg', 'overall', 'been', 'sometimes', 'where', 'get', 'hereafter', 'three', 'g', 'seven', 'quite', 'towards', 'may', 'thereafter', 'beside', 'noone', 'none', 'be', 'help', 'accordingly', 'anywhere', 'further', 'specifying', 'toward', \"you'll\", 'hopefully', 'what', 'my', 'p', 'beforehand', 'there', 'secondly', \"we're\", 'thence', 'ignored', 'forth', 'way', 'indicated', 'together', 'four', 'hardly', 'useful', 'kept', 'sub', 'yes', 'among', 'at', 'q', 'ex', 'such', 'considering', 't', 'using', 'something', 'ourselves', 'r', \"wouldn't\", 'keep', 'tell', 'y', 'another', 'clearly', 'onto', 'given', 'latterly', 'especially', 'seeing', 'appropriate', 'later', 'had', 'or', 'provides', 'only', 'whenever', 'anyways', 'soon', 'also', 'see', 'best', 'whither', \"aren't\", 'less', 'allows', 'lest', 'much', 'n', 'others', 'should', 'immediate', 'around', 'sometime', 'although', 'example', 'seem', 'entirely', \"they're\", 'que', 'l', 'of', 'oh', 'down', 'five', 'them', 'allow', 'on', \"you'd\", 'followed', 'yours', 'come', 'somewhat', 'tried', 'very', 'thoroughly', 'various', 'shall', \"weren't\", 'e', \"it'll\", 'through', 'wherever', 'most', 'cannot', \"it's\", 'outside', 'here', 'namely', \"don't\", 'v', 'mostly', 'per', 'during', 'whoever', 'out', 'we', \"let's\", 'course', 'second', 'qv', 'little', 'appreciate', 'want', 'both', 're', 'h', 'old', 'm', 'anyhow', 'after', 'trying', 'everyone', 'often', 'done', 'know', 'regards', 'w', 'concerning', 'presumably', \"they'd\", \"ain't\", 'latter', 'seems', 'might', 'now', 'take', 'unto', 'says', 'certain', \"won't\", 'every', 'own', 'truly', 'non', 'becomes', 'sent', 'likely', 'ok', 'all', 'sorry', 'which', 'indeed', 'thats', 'nor', 'downwards', 'other', 'almost', 'unfortunately', 'hereupon', 'who', 'wonder', 'nowhere', \"here's\", 'willing', \"i'm\", 'zero', 'rd', 'com', 'different', 'changes', 'said', 'too', 'exactly', 'tries', 'x', \"didn't\", 'he', 'vs', 'i', \"it'd\", 'particular', 'its', 'inasmuch', 'those', 'probably', 'the', 'contain', 'it', 'first', 'herein', 'instead', 'ones', 'indicate', 'just', 'specify', \"a's\", 'over', 'have', 'and', \"we'd\", 'specified', 'when', 'relatively', 'below', 'if', 'theirs', 'f', 'behind', 'whom', 'are', 'will', \"where's\", 'from', 'into', 'enough', 'your', 'least', 'anyway', 'un', \"t's\", 'cause', 'herself', 'keeps', 'ought', 'has', 'within', 'comes', 'once', 'novel', 'anything', 'known', 'afterwards', 'aside', 'look', 'being', 'off', 'across', 'mean', 'respectively', 'value', 'two', 'otherwise', 'regarding', 'without', 'follows', 'ltd'}\n",
      "{'name': 'Composites technology', 'description': \"The latest developments in processing and the novel generations of organic composites are discussed. Nanocomposites, adaptive composites and biocomposites are presented. Product development, cost analysis and study of new markets are practiced in team work. Content Basics of composite materialsConstituentsProcessing of compositesDesign of composite structures\\xa0Current developmentNanocomposites Textile compositesBiocompositesAdaptive composites\\xa0ApplicationsDriving forces and marketsCost analysisAerospaceAutomotiveSport Keywords Composites - Applications - Nanocomposites - Biocomposites - Adaptive composites - Design - Cost Learning Prerequisites Required courses Notion of polymers Recommended courses Polymer Composites Learning Outcomes By the end of the course, the student must be able to: Propose suitable design, production and performance criteria for the production of a composite partApply the basic equations for process and mechanical properties modelling for composite materialsDiscuss the main types of composite applications Transversal skills Use a work methodology appropriate to the task.Use both general and domain specific IT resources and toolsCommunicate effectively with professionals from other disciplines.Evaluate one's own performance in the team, receive and respond appropriately to feedback. Teaching methods Ex cathedra and invited speakers Group sessions with exercises or work on the project Expected student activities Attendance at lectures Design of a composite part, bibliography search \\xa0 Assessment methods Written exam report and oral presentation in class\", 'courseId': 'MSE-440'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "import string\n",
    "import math\n",
    "import collections\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "print(stopwords)\n",
    "print(courses[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this intends teach image processing strong emphasis applications life sciences the idea enable participants solve image processing questions workflows independently content over decades images arising microscopes life sciences qualitative support scientific evidence quantitative resource to obtain good quality data digital images photograph western blot tem slice multichannel confocal timelapse stack scientists understand underlying processes leading extracted information of similar importance software obtain data this makes imagej fiji package opensource tools ensure maximum reproducibility protocol transfer analysis pipelines the span 14 weeks 1h30 lecture week exercises complete enable students establish image analysis workflows autonomously note this open max 16 students selected organizer this 14week aims introduce students digital image analysis context life sciences we cover topics digital image data representations formats metadata image manipulation macro script creation filtering linear nonlinear morphological segmentation regions interest image stitching image visualisation data extraction representation image deconvolution denoising machine learning each topic strong emphasis good practices exercises handed session exercises involve creation macros scripts reach defined goal the exercises completed autonomous homework lecture hours keywords biology image processing microscopy imagej fiji macros data segmentationfiltering visualisation open assessment methods continuous multiple\n"
     ]
    }
   ],
   "source": [
    "newCourses =[]\n",
    "ps = PorterStemmer()\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for course in courses:\n",
    "    temp = course['description']\n",
    "    for word in stopwords:\n",
    "        temp = temp.replace(' '+word+' ',' ')\n",
    "    temp = temp.translate(translator)\n",
    "    stemList = []\n",
    "    #for word in temp.split(' '):\n",
    "    #    stemList.append(ps.stem(word))\n",
    "    #temp = ' '.join(stemList)\n",
    "        \n",
    "    newCourses.append({'name':course['name'],'description':temp})\n",
    "print(newCourses[1]['description'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-19dff374736e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtermFreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcountDoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountDocWithTerm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewCourses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcountDoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermFreq\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-19dff374736e>\u001b[0m in \u001b[0;36mcountDocWithTerm\u001b[0;34m(term, docs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def countDocWithTerm(term,docs):\n",
    "    result = 0\n",
    "    for doc in docs:\n",
    "        if term in doc['description'].split(' '):\n",
    "            result += 1\n",
    "    return result\n",
    "            \n",
    "\n",
    "terms =[]\n",
    "for item in newCourses:\n",
    "    for word in item['description'].split(' '):\n",
    "        terms.append(word)\n",
    "terms = list(collections.Counter(terms).keys())\n",
    "terms.remove('')\n",
    "matrix = []\n",
    "for i,term in enumerate(terms):\n",
    "    temp =[]\n",
    "    countDoc = 0\n",
    "    for document in newCourses:\n",
    "        count = 0\n",
    "        for word in document['description'].split(' '):\n",
    "            if word == term:\n",
    "                count += 1\n",
    "        termFreq = count/len(document['description'].split(' '))\n",
    "        countDoc = countDocWithTerm(term,newCourses)\n",
    "        idf = math.log(len(newCourses)/countDoc)\n",
    "        temp.append(termFreq*idf)\n",
    "    matrix.append(temp)\n",
    "print(matrix[0])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *P*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Matthias Leroy*\n",
    "* *Pierre Fouche*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"ex3.pickle\", \"rb\") as f:\n",
    "    courses = pickle.load(f, encoding=\"utf-8\")\n",
    "#Load the courses\n",
    "data = sc.parallelize(courses)\n",
    "#Retrieve the list of words for each course\n",
    "data = data.map(lambda x: x['listDescription'])\n",
    "#Remove doublons\n",
    "termCounts = data.flatMap(lambda x:x).map(lambda x : (x,1)).reduceByKey(lambda a,b:a+b).map(lambda x:(x[1],x[0])).sortByKey(False)\n",
    "#Create dic with word as key and indes as value\n",
    "voc = termCounts.map(lambda x:x[1]).zipWithIndex().collectAsMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list that is the size of the vocabulary, \n",
    "# and the value of each cell is the count of the word whose id is the index of that cell\n",
    "def document_vector(document):\n",
    "    id = document[1]\n",
    "    counts = defaultdict(int)\n",
    "    for token in document[0]:\n",
    "        if token in voc:\n",
    "            token_id = voc[token]\n",
    "            counts[token_id] += 1\n",
    "    counts = sorted(counts.items())\n",
    "    keys = [x[0] for x in counts]\n",
    "    values = [x[1] for x in counts]\n",
    "    return (id, Vectors.sparse(len(voc), keys, values))\n",
    "\n",
    "documents = data.zipWithIndex().map(document_vector).map(list)\n",
    "inv_voc = {value: key for (key, value) in voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute lda with the differents parameters\n",
    "def trainLda(cluster = 10 ,alpha =- 1.0, beta = -1.0):\n",
    "    lda_model = LDA.train(documents,k = cluster, docConcentration=alpha,topicConcentration=beta)\n",
    "    result =lda_model.describeTopics(10)\n",
    "    for i in range(len(result)):\n",
    "        print('topic',(i+1),'=================')\n",
    "        for j in range(len(result[i][0])):\n",
    "            print(inv_voc[result[i][0][j]])\n",
    "trainLda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 1: Engineering, Topic 2: Physics/Chemistry, Topic 3: Presentation, Topic 4: Algorithm, Topic 5: Methodology, Topic 6: Machine Learning, Topic 7: Mathematics, Topic 8: Electronic System, Topic 9: Stochastic Model, Topic 10: Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainLda(cluster=12,alpha=6.0,beta=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try some alphas\n",
    "for a in np.linspace(1.01,6,11):\n",
    "    print(a,\" 1.01\")\n",
    "    print(\"=========================\")\n",
    "    trainLda(alpha=a,beta=1.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high value of alpha leads to more precise topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try some betas\n",
    "for b in np.linspace(1.01,6,11):\n",
    "    print(\"6.0 \",b)\n",
    "    print(\"=========================\")\n",
    "    trainLda(alpha =6.0, beta=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high value of beta leads to topics being more similar in terms of what words they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find the best k, alpha and beta\n",
    "for k in [12,15,18]:\n",
    "    for a in np.linspace(1.01,6.01,3):\n",
    "        for b in np.linspace(1.01,6.01,3):\n",
    "            print(a,b,k)\n",
    "            print(\"===========================================================================\")\n",
    "            trainLda(k,a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLda(cluster=12,alpha=6.0,beta=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose k=12 because there are approximately 12 differents sections in EPFL, alpha=6 because we want precise topics and beta = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki = sc.textFile(\"/ix/wikipedia-for-schools.txt\").map(json.loads)\n",
    "data = wiki.map(lambda x: x['tokens'])\n",
    "termCounts = data.flatMap(lambda x:x).map(lambda x : (x,1)).reduceByKey(lambda a,b:a+b).map(lambda x:(x[1],x[0])).sortByKey(False)\n",
    "voc = termCounts.map(lambda x:x[1]).zipWithIndex().collectAsMap()\n",
    "documents = data.zipWithIndex().map(document_vector).map(list)\n",
    "inv_voc = {value: key for (key, value) in voc.items()}\n",
    "\n",
    "trainLda(12,8.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose k = 12 because Wikipedia has 12 portals.<br/>\n",
    "Topic 1: General, Topic 2: Society,  Topic 3: Animals , Topic 4: Natural Science , Topic 5: Religions, Topic 6:Technologies, Topic 7:Globalization, Topic 8: Mathematics, Topic 9: Arts, Topic 10: History, Topic 11: Culture, Topic 12: Physics sciences\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

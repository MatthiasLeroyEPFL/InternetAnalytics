{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** P\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Matthias Leroy\n",
    "* Pierre Fouche\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We get from the disc the term-document matrix X\n",
    "#as well as the dictionaries that link terms and document(courses) with their indices\n",
    "with open(\"matrix.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f, encoding=\"utf-8\")\n",
    "with open(\"newCoursesDict.pickle\", \"rb\") as f:\n",
    "    newCoursesDict = pickle.load(f, encoding=\"utf-8\")\n",
    "with open(\"termsDict.pickle\", \"rb\") as f:\n",
    "    termsDict = pickle.load(f, encoding=\"utf-8\")\n",
    "\n",
    "# we apply SVD with K = 300 to our term-document matrix X.\n",
    "U,S,Vt = svds(X,300)\n",
    "print([e*e for e in S[-20:][::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Each singular value of S describe the importance of some concept/topics, thus the highest values correspond to the most significance concept.<br/>\n",
    "The columns of U describe a concept among all the terms of our matrix. Thus its rows define the terms.<br/>\n",
    "The rows of Vt describe a concept among all the documents of our matrix. This its columns define the documents<br/>\n",
    "\n",
    "\n",
    "\n",
    "2) The top-20 eigenvalues of X are the 20 biggest square of the singular value of S: see above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topicTermDict = {}\n",
    "indiceT = 1\n",
    "#we get the columns of U corresponding to the highest singular value of S.\n",
    "#then we look for the 10 most important terms inside each topic\n",
    "for topicTerm in np.absolute(np.transpose(U))[-10:][::-1]:\n",
    "    idxTerms = topicTerm.argsort()[-10:][::-1]\n",
    "    tempList1 = []\n",
    "    for idxT in idxTerms:\n",
    "        term = termsDict[idxT]\n",
    "        tempList1.append(term)\n",
    "    topicTermDict[indiceT]=tempList1\n",
    "    indiceT+=1\n",
    "    \n",
    "indiceD = 1\n",
    "topicDocDict = {}\n",
    "#we get the columns of Vt corresponding to the highest singular value of S.\n",
    "#then we look for the 10 most important document(class) inside each topic\n",
    "for topicDoc in np.absolute(Vt)[-10:][::-1]:\n",
    "    idxDoc = topicDoc.argsort()[-10:][::-1]\n",
    "    tempList2 = []\n",
    "    for idxD in idxDoc:\n",
    "        doc = newCoursesDict[idxD]['name']\n",
    "        tempList2.append(doc)\n",
    "    topicDocDict[indiceD]=tempList2\n",
    "    indiceD+=1\n",
    "\n",
    "\n",
    "for i in range(1,11):\n",
    "    print('Terms for topic',i,'\\n')\n",
    "    for j in range(10):\n",
    "        print(topicTermDict[i][j])\n",
    "    print('\\nDocument for topic',i,'\\n')\n",
    "    for k in range(10):\n",
    "        print(topicDocDict[i][k])\n",
    "    print('------------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\n",
    "\n",
    "label topic 1: Visual computing<br/>\n",
    "label topic 2: Medical science<br/>\n",
    "label topic 3: Bio electronic<br/>\n",
    "label topic 4: Thermodynamics<br/>\n",
    "label topic 5: Electromagnetism<br/>\n",
    "label topic 6: Physical waves<br/>\n",
    "label topic 7: General physics<br/>\n",
    "label topic 8: Astrophysics<br/>\n",
    "label topic 9: Biological fluid<br/>\n",
    "label topic 10: Fluid experimentation<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that compute the similarity between a term of index t and a document of index d\n",
    "def similarity(t,d):\n",
    "    Urow = U[t].reshape(1,300)\n",
    "    Sdiag = np.diag(S)\n",
    "    Vrow = Vt[:,d].reshape(300,1)\n",
    "    Svd = np.dot(Sdiag,Vrow)\n",
    "    \n",
    "    sim = (np.dot(Urow,Svd))/(np.linalg.norm(Urow)*np.linalg.norm(Svd))\n",
    "    return sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "#Function that find the index of a terms\n",
    "def findIndexTerm(q):\n",
    "    b=0\n",
    "    for key,value in termsDict.items():\n",
    "        if value == ps.stem(q):\n",
    "            b = key\n",
    "            break;\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Search function that compare the similarity between a given term and all the classes\n",
    "#it print the top 10 of courses with it score of similarity with the term\n",
    "def searchFunction(query):\n",
    "    t = findIndexTerm(query)\n",
    "    resultSim = []\n",
    "    \n",
    "    for d,doc in newCoursesDict.items():        \n",
    "        resultSim.append((doc['name'],similarity(t,d)))\n",
    "    \n",
    "    sorted_by_similarity = sorted(resultSim, key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    return(sorted_by_similarity[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we search for facebook\n",
    "for result in searchFunction('facebook'):\n",
    "    print('class:',result[0])\n",
    "    print('score:', result[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) With VSM in the first exercise, when we have searched facebook, we find only one class that match because only the course of 'Computational Social Media' have the term facebook in its description. However with LSI we have connected other terms with facebook, thus it returns all the courses that are connected to the same idea (like social media for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we search for markov chains\n",
    "for result in searchFunction('markov chains'):\n",
    "    print('class:',result[0])\n",
    "    print('score:', result[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We find the same courses but with other one that could be interesting without explicitly talking about marking chain (at least in their description)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "for key,value in newCoursesDict.items():\n",
    "    if value['name'] == 'Internet analytics':\n",
    "        a = key\n",
    "        break;\n",
    "        \n",
    "resultSim2 = []\n",
    "    \n",
    "for i,terms in termsDict.items():        \n",
    "    resultSim2.append((terms,similarity(i,a)))\n",
    "    \n",
    "sorted_by_similarity2 = sorted(resultSim2, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "coursesSim = []\n",
    "for n,s in sorted_by_similarity2[:300]:\n",
    "    for c,s2 in searchFunction(n):\n",
    "        coursesSim.append((c,s+s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections as col\n",
    "\n",
    "c = col.Counter()\n",
    "for k, v in coursesSim:\n",
    "    c[k] += v\n",
    "\n",
    "sortCourses = sorted(c.items(), key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "for course,score in sortCourses[1:6]:\n",
    "    print(course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We have gotten the 5 first courses similar to COM 308 by combining the terms with the best similarity scores with Internet Analitics and the similarity scores of these terms with all the other courses.\n",
    "\n",
    "2)Thus we have find:<br/><br/>\n",
    "Applied data analysis<br/>\n",
    "Distributed information systems<br/>\n",
    "A Network Tour of Data Science<br/>\n",
    "Data science for business<br/>\n",
    "Database systems<br/>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

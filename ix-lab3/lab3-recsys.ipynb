{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 â€” recommender systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /ix/ml-20m/ratings.txt | tail -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"/ix/ml-20m/ratings.txt\").map(json.loads)\n",
    "user = data.map(itemgetter('userId'))\n",
    "user = user.map(lambda x: (x,1))\n",
    "user = user.reduceByKey(lambda a,b: a+b)\n",
    "item = data.map(itemgetter('movieId'))\n",
    "item = item.map(lambda x: (x,1))\n",
    "item = item.reduceByKey(lambda a,b:a+b)\n",
    "item = item.map(lambda x: x[1])\n",
    "user = user.map(lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = (user.collect())\n",
    "y = (item.collect())\n",
    "plt.plot(sorted(x))\n",
    "plt.show()\n",
    "plt.plot(sorted(y))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ratings are not balanced uniformly accros users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run rate-movies.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -put my-ratings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create trainig and validation st\n",
    "myRates = sc.textFile('my-ratings.txt').map(json.loads)\n",
    "newData = data.union(myRates)\n",
    "count = newData.count()\n",
    "trainingSet = data.filter(lambda x: x['timestamp']%10 <= 7)\n",
    "validationSet = data.filter(lambda x: x['timestamp']%10 > 7)\n",
    "mean = trainingSet.map(lambda x: x['rating']).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute user bias\n",
    "userBias = trainingSet.map(lambda x:(x['userId'],x['rating']-mean)).groupByKey().map(lambda x:(x[0],sum(x[1])/len(x[1]))).collect()\n",
    "\n",
    "userBiasDic = {}\n",
    "for item in userBias:\n",
    "    userBiasDic[item[0]] = item[1]\n",
    "users = newData.map(lambda x: x['userId']).distinct().collect()\n",
    "for user in users:\n",
    "    if user not in userBiasDic.keys():\n",
    "        userBiasDic[user] = 0\n",
    "#Compute item bias\n",
    "itemBias = trainingSet.map(lambda x: (x['movieId'],x['rating']-mean-userBiasDic[x['userId']])).groupByKey().map(lambda x:(x[0],sum(x[1])/len(x[1]))).sortByKey().collect()\n",
    "itemBiasDic = {}\n",
    "for item in itemBias:\n",
    "    itemBiasDic[item[0]] = item[1] \n",
    "movies = newData.map(lambda x: x['movieId']).distinct().collect()\n",
    "for movie in movies:\n",
    "    if movie not in itemBiasDic.keys():\n",
    "        itemBiasDic[movie] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute predicted ratings\n",
    "rating = validationSet.map(lambda x: (x['movieId'],x['userId'],mean+userBiasDic[x['userId']]+itemBiasDic[x['movieId']])).collect()\n",
    "ratingDic = {}\n",
    "for item in rating:\n",
    "    ratingDic[(item[0],item[1])] = item[2]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(ratings):\n",
    "    print(ratings)\n",
    "    temp = validationSet.map(lambda x:(x['userId'],pow(ratings[(x['movieId'],x['userId'])]-x['rating'],2))).groupByKey().map(lambda x:sum(x[1])/len(x[1])).sum()\n",
    "    nbrUser = validationSet.map(lambda x:x['userId']).distinct().count()\n",
    "    err = temp / nbrUser\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(error(ratingDic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8500001435"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a low rank, the result is less precise but the computation is fast. It is the opposite with high rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Try to find the best lambda\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "lambdas = np.arange(0.01,0.1,0.01)\n",
    "minErr = 500\n",
    "bestLambda = 0\n",
    "for lamb in lambdas:\n",
    "    matrix = ALS.train(newData.map(lambda x:(x['userId'],x['movieId'],x['rating'])),12,lambda_=lamb)\n",
    "    result = matrix.predictAll(validationSet.map(lambda x:(x['userId'],x['movieId']))).collect()\n",
    "    resultDic = {}\n",
    "    for item in result:\n",
    "        resultDic[(item[1],item[0])] = item[2]\n",
    "    err = error(resultDic)\n",
    "    print(err,\" with lambda =\",lamb)\n",
    "    if err<minErr:\n",
    "        bestLambda = lamb\n",
    "        minErr = err\n",
    "    \n",
    "    \n",
    "print(minErr,bestLambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top10For123 = matrix.recommendProducts(123,10)\n",
    "temp =[]\n",
    "for item in top10For123:\n",
    "    temp.append(item[1])\n",
    "file = sc.textFile(\"/ix/ml-20m/movies.txt\").map(json.loads)\n",
    "resultMovies =[]\n",
    "file = file.filter(lambda x: x['movieId'] in temp).map(lambda x: (x['title'],x['genres'])).collect()\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the user 123 likes the drama movies"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
